{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.datasets import cifar10\n",
    "import autokeras as ak\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "from autokeras.utils import pickle_from_file\n",
    "from keras.models import load_model\n",
    "from thop import profile    #pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runMain():\n",
    "    # load the training and testing data, then scale it into the\n",
    "    # range [0, 1]\n",
    "    print(datetime.datetime.now())\n",
    "    print(\"[INFO] loading CIFAR-10 data...\")\n",
    "    ((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "    trainX = trainX.astype(\"float\") / 255.0\n",
    "    testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "    # initialize the label names for the CIFAR-10 dataset\n",
    "    labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "        \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "    # initialize the output directory\n",
    "    OUTPUT_PATH = \"output\"\n",
    "\n",
    "    seconds= 3*60*60 #1 hour\n",
    "    print(datetime.datetime.now())\n",
    "    print(\"[INFO] training model for {} seconds max...\".format(seconds))\n",
    "    model = ak.ImageClassifier(path=os.path.join(os.getcwd(),\"automodels\"),verbose=True)\n",
    "    model.fit(trainX, trainY, time_limit=seconds)\n",
    "    print(datetime.datetime.now())\n",
    "    #saveModel(model)\n",
    "    # print(\"[INFO] final_fit\")\n",
    "    # model.final_fit(trainX, trainY, testX, testY, retrain=True)\n",
    "\n",
    "    # evaluate the Auto-Keras model\n",
    "    # score = model.evaluate(testX, testY)\n",
    "    # predictions = model.predict(testX)\n",
    "    # report = classification_report(testY, predictions,target_names=labelNames)\n",
    " \n",
    "# write the report to disk\n",
    "# p = os.path.join(OUTPUT_PATH, \"{}.txt\".format(seconds))\n",
    "# f = open(p, \"w\")\n",
    "# f.write(report)\n",
    "# f.write(\"\\nscore: {}\".format(score))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model):\n",
    "    return profile(model, input_size=(1, 3, 32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModule():\n",
    "    path = os.path.join('automodels', 'module')\n",
    "    cnn_module = pickle_from_file(path)\n",
    "    return cnn_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelData(module):\n",
    "    for item in module.searcher.history:  \n",
    "        model_id = item['model_id']\n",
    "        graph = module.searcher.load_model_by_id(model_id)\n",
    "        model = graph.produce_model()\n",
    "        print(model)\n",
    "        flops, params = get_flops(model)\n",
    "        file_path=os.path.join('automodels', \"{}.pt\".format(model_id))\n",
    "        torch.save(model.state_dict(), file_path)\n",
    "        pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        print(\"\\nmodel Id {}:\\n   total params = {}\\n   file size = {} kB\\n   flops: {}\".format(model_id,pytorch_total_params, file_size/1000, flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-28 06:35:05.286888\n",
      "[INFO] loading CIFAR-10 data...\n",
      "2019-05-28 06:35:06.893118\n",
      "[INFO] training model for 10800 seconds max...\n",
      "Saving Directory: /home/Yuval_workspace/Nexar/automodels\n",
      "Preprocessing the images.\n",
      "Preprocessing finished.\n",
      "\n",
      "Initializing search.\n",
      "Initialization finished.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 0               |\n",
      "+----------------------------------------------+\n",
      "                                                                                                    \n",
      "No loss decrease after 5 epochs.\n",
      "\n",
      "\n",
      "Saving model.\n",
      "+--------------------------------------------------------------------------+\n",
      "|        Model ID        |          Loss          |      Metric Value      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|           0            |   3.9143118500709533   |          0.66          |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 1               |\n",
      "+----------------------------------------------+\n",
      "Epoch-1, Current Metric - 0:  28%|███████▉                    | 110/387 [10:16<27:24,  5.94s/ batch]Time is out.\n",
      "2019-05-28 09:35:20.838429\n"
     ]
    }
   ],
   "source": [
    "runMain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (0): ReLU()\n",
      "  (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): ReLU()\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): ReLU()\n",
      "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (12): GlobalAvgPool2d()\n",
      "  (13): Dropout2d(p=0.25)\n",
      "  (14): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (15): ReLU()\n",
      "  (16): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Register FLOP counter for module MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Register FLOP counter for module MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Register FLOP counter for module MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Not implemented for  GlobalAvgPool2d()\n",
      "Not implemented for  Dropout2d(p=0.25)\n",
      "Register FLOP counter for module Linear(in_features=64, out_features=64, bias=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Linear(in_features=64, out_features=10, bias=True)\n",
      "\n",
      "model Id 0:\n",
      "   total params = 80720\n",
      "   file size = 332.093 kB\n",
      "   flops: 15243510.0\n"
     ]
    }
   ],
   "source": [
    "getModelData(getModule())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
